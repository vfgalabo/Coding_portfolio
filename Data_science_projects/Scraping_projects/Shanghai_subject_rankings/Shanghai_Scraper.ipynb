{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbaefedb-c981-4088-91e4-d34132e0dca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import csv\n",
    "import threading\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91a9b19-3f72-4bef-a8c3-bbff2aa54b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Scraper ---\n",
      "Scraping Economics for year 2025...\n",
      "Scraping page 1\n",
      "Scraping page 2\n",
      "Scraping page 3\n",
      "Scraping page 4\n",
      "Scraping page 5\n",
      "Scraping page 6\n",
      "Scraping page 7\n",
      "Scraping page 8\n",
      "Scraping page 9\n",
      "Scraping page 10\n",
      "Scraping page 11\n",
      "Scraping page 12\n",
      "Scraping page 13\n",
      "Scraping page 14\n",
      "Scraping page 15\n",
      "Scraping page 16\n",
      "Scraping page 17\n",
      "Reached the last page for year 2025. Exiting Loop\n",
      "Successfully extracted 500 rows.\n",
      "Scraping Statistics for year 2025...\n",
      "Scraping page 1\n",
      "Scraping page 2\n",
      "Scraping page 3\n",
      "Scraping page 4\n",
      "Scraping page 5\n",
      "Scraping page 6\n",
      "Scraping page 7\n",
      "Scraping page 8\n",
      "Scraping page 9\n",
      "Scraping page 10\n",
      "Reached the last page for year 2025. Exiting Loop\n",
      "Successfully extracted 300 rows.\n",
      "Scraping Law for year 2025...\n",
      "Scraping page 1\n",
      "Scraping page 2\n",
      "Scraping page 3\n",
      "Scraping page 4\n",
      "Scraping page 5\n",
      "Scraping page 6\n",
      "Scraping page 7\n",
      "Reached the last page for year 2025. Exiting Loop\n",
      "Successfully extracted 200 rows.\n",
      "Scraping Political Sciences for year 2025...\n",
      "Scraping page 1\n",
      "Scraping page 2\n",
      "Scraping page 3\n",
      "Scraping page 4\n",
      "Scraping page 5\n",
      "Scraping page 6\n",
      "Scraping page 7\n",
      "Scraping page 8\n",
      "Scraping page 9\n",
      "Scraping page 10\n",
      "Reached the last page for year 2025. Exiting Loop\n",
      "Successfully extracted 300 rows.\n",
      "Scraping Sociology for year 2025...\n",
      "Scraping page 1\n",
      "Scraping page 2\n",
      "Scraping page 3\n",
      "Scraping page 4\n",
      "Scraping page 5\n",
      "Scraping page 6\n",
      "Scraping page 7\n",
      "Scraping page 8\n",
      "Scraping page 9\n",
      "Scraping page 10\n",
      "Reached the last page for year 2025. Exiting Loop\n",
      "Successfully extracted 300 rows.\n",
      "Scraping Education for year 2025...\n",
      "Scraping page 1\n",
      "Scraping page 2\n",
      "Scraping page 3\n",
      "Scraping page 4\n",
      "Scraping page 5\n",
      "Scraping page 6\n",
      "Scraping page 7\n",
      "Scraping page 8\n",
      "Scraping page 9\n",
      "Scraping page 10\n",
      "Scraping page 11\n",
      "Scraping page 12\n",
      "Scraping page 13\n",
      "Scraping page 14\n",
      "Scraping page 15\n",
      "Scraping page 16\n",
      "Scraping page 17\n",
      "Reached the last page for year 2025. Exiting Loop\n",
      "Successfully extracted 500 rows.\n",
      "Scraping Communication for year 2025...\n",
      "Scraping page 1\n",
      "Scraping page 2\n",
      "Scraping page 3\n",
      "Scraping page 4\n",
      "Scraping page 5\n",
      "Scraping page 6\n",
      "Scraping page 7\n",
      "Reached the last page for year 2025. Exiting Loop\n",
      "Successfully extracted 200 rows.\n",
      "Scraping Psychology for year 2025...\n",
      "Scraping page 1\n",
      "Scraping page 2\n",
      "Scraping page 3\n",
      "Scraping page 4\n",
      "Scraping page 5\n",
      "Scraping page 6\n",
      "Scraping page 7\n",
      "Scraping page 8\n",
      "Scraping page 9\n",
      "Scraping page 10\n",
      "Scraping page 11\n",
      "Scraping page 12\n",
      "Scraping page 13\n",
      "Scraping page 14\n",
      "Scraping page 15\n",
      "Scraping page 16\n",
      "Scraping page 17\n",
      "Reached the last page for year 2025. Exiting Loop\n",
      "Successfully extracted 500 rows.\n",
      "Scraping Business Administration for year 2025...\n",
      "Scraping page 1\n",
      "Scraping page 2\n",
      "Scraping page 3\n",
      "Scraping page 4\n",
      "Scraping page 5\n",
      "Scraping page 6\n",
      "Scraping page 7\n",
      "Scraping page 8\n",
      "Scraping page 9\n",
      "Scraping page 10\n",
      "Scraping page 11\n",
      "Scraping page 12\n",
      "Scraping page 13\n",
      "Scraping page 14\n",
      "Reached the last page for year 2025. Exiting Loop\n",
      "Successfully extracted 400 rows.\n",
      "Scraping Finance for year 2025...\n",
      "Scraping page 1\n",
      "Scraping page 2\n",
      "Scraping page 3\n",
      "Scraping page 4\n",
      "Scraping page 5\n",
      "Scraping page 6\n",
      "Scraping page 7\n",
      "Reached the last page for year 2025. Exiting Loop\n",
      "Successfully extracted 200 rows.\n",
      "Scraping Management for year 2025...\n",
      "Scraping page 1\n",
      "Scraping page 2\n",
      "Scraping page 3\n",
      "Scraping page 4\n",
      "Scraping page 5\n",
      "Scraping page 6\n",
      "Scraping page 7\n",
      "Scraping page 8\n",
      "Scraping page 9\n",
      "Scraping page 10\n",
      "Scraping page 11\n",
      "Scraping page 12\n",
      "Scraping page 13\n",
      "Scraping page 14\n",
      "Scraping page 15\n",
      "Scraping page 16\n",
      "Scraping page 17\n",
      "Reached the last page for year 2025. Exiting Loop\n",
      "Successfully extracted 500 rows.\n",
      "Scraping Public Administration for year 2025...\n",
      "Scraping page 1\n",
      "Scraping page 2\n",
      "Scraping page 3\n",
      "Scraping page 4\n",
      "Reached the last page for year 2025. Exiting Loop\n",
      "Successfully extracted 100 rows.\n",
      "Scraping Hospitality & Tourism Management for year 2025...\n",
      "Scraping page 1\n",
      "Scraping page 2\n",
      "Scraping page 3\n",
      "Scraping page 4\n",
      "Reached the last page for year 2025. Exiting Loop\n",
      "Successfully extracted 100 rows.\n",
      "Scraping Library & Information Science for year 2025...\n",
      "Scraping page 1\n",
      "Scraping page 2\n",
      "Scraping page 3\n",
      "Scraping page 4\n",
      "Reached the last page for year 2025. Exiting Loop\n",
      "Successfully extracted 100 rows.\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "base_url = \"https://www.shanghairanking.com/rankings/gras/{year}/{subject_code}\"\n",
    "output_folder = \"ShanghaiRanking\" # suggested output folder name\n",
    "\n",
    "# --- Create Output Folder and Initialize WebDriver ---\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--headless')\n",
    "options.add_argument('--disable-gpu') \n",
    "options.add_argument('--no-sandbox') \n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "# --- Subject Codes ----\n",
    "subject_codes = { \n",
    "    \"AS0101\" : \"Mathematics\",\n",
    "    \"AS0513\" : \"Hospitality & Tourism Management\",\n",
    "    \"AS0515\" : \"Library & Information Science\"\n",
    "    # ... add other subjects as needed; subject code \"ASXXXX\" (found in the URL of the specific subject) : \"Subject Name\"\n",
    "}\n",
    "    \n",
    "# --- Dropdown Options ---\n",
    "dropdown_options_2025 = [\n",
    "    \"World-Class Output\",\n",
    "    \"High Quality Research\",\n",
    "    \"Research Impact\",\n",
    "    \"International Collaboration\",\n",
    "]\n",
    "# --- NB: For years before 2024, the criteria options are different ---\n",
    "dropdown_options_other = [\n",
    "    \"CNCI\", \n",
    "    \"IC\", \n",
    "    \"TOP\", \n",
    "    \"AWARD\"\n",
    "]\n",
    "\n",
    "def scrape_subject(year, subject_code, subject_name, driver):\n",
    "    url = base_url.format(year=year, subject_code=subject_code)\n",
    "    output_filename = f\"{subject_name}_{year}.csv\"\n",
    "    file_path = os.path.join(output_folder, output_filename)\n",
    "\n",
    "    print(f\"Scraping {subject_name} for year {year}...\")\n",
    "\n",
    "    # Navigate and wait for the table\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \"table.rk-table tbody tr\"))\n",
    "        )\n",
    "    except TimeoutException:\n",
    "        print(f\"Timeout: Table data not found for {subject_name} in {year}. Skipping.\")\n",
    "        return\n",
    "\n",
    "    # --- Setup Headers and Dynamic Criteria Lists ---\n",
    "    with open(file_path, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        \n",
    "        if year >= 2025:\n",
    "            header = [\n",
    "                \"Rank\", \"Institution\", \"Country/Region\", \"Total Score\",\n",
    "                \"World-Class Faculty\", \"World-Class Output\", \"High Quality Research\", \n",
    "                \"Research Impact\", \"International Collaboration\",\n",
    "            ]\n",
    "            default_criteria_key = \"World-Class Faculty\"\n",
    "            # List contains all 5 options, starting with the default one\n",
    "            criteria_options_to_click_all = [default_criteria_key] + dropdown_options_2025 \n",
    "            # Note that the data from year < 2024 appears with different criteria options, so we handle them separately\n",
    "        else:    \n",
    "            header = [\n",
    "                \"Rank\", \"Institution\", \"Country/Region\", \"Total Score\",\n",
    "                \"Q1\", \"CNCI\", \"IC\", \"TOP\", \"AWARD\",\n",
    "            ]\n",
    "            default_criteria_key = \"Q1\"\n",
    "            criteria_options_to_click_all = [default_criteria_key] + dropdown_options_other\n",
    "\n",
    "        writer.writerow(header)\n",
    "        \n",
    "        all_data_collected = []\n",
    "        page_num = 1\n",
    "        \n",
    "        while True:\n",
    "            print(f\"Scraping page {page_num}\")\n",
    "            current_page_data = []\n",
    "            unscored_row_indices = []\n",
    "            \n",
    "            # --- Initial Extraction (Default View) ---\n",
    "            rows = driver.find_elements(By.CSS_SELECTOR, \"table.rk-table tbody tr\")\n",
    "            \n",
    "            for i, row in enumerate(rows):\n",
    "                data = {}\n",
    "                \n",
    "                try:\n",
    "                    # Basic Data (td[1] to td[3])\n",
    "                    data[\"Rank\"] = row.find_element(By.XPATH, \"./td[1]\").text.strip()\n",
    "                    data[\"Institution\"] = row.find_element(By.XPATH, \"./td[2]\").text.strip()\n",
    "                    country_element = row.find_element(By.XPATH, \"./td[3]/div\")\n",
    "                    style_attr = country_element.get_attribute(\"style\")\n",
    "                    data[\"Country/Region\"] = style_attr.split(\"/\")[-1].split(\".\")[0] if style_attr else \"\"\n",
    "\n",
    "                    # Total Score (td[4])\n",
    "                    total_score_text = row.find_element(By.XPATH, \"./td[4]\").text.strip()\n",
    "                    data[\"Total Score\"] = total_score_text if total_score_text else \"\"\n",
    "\n",
    "                    # Default Criteria (td[5])\n",
    "                    default_text = row.find_element(By.XPATH, \"./td[5]\").text.strip()\n",
    "                    \n",
    "                    if not data[\"Total Score\"]:\n",
    "                        # If unscored, mark for forced re-scrape and temporarily clear the default value\n",
    "                        data[default_criteria_key] = \"\" \n",
    "                        unscored_row_indices.append(i)\n",
    "                    else:\n",
    "                        # If scored, save the initial correct value\n",
    "                        data[default_criteria_key] = default_text if default_text else \"\"\n",
    "                    \n",
    "                except NoSuchElementException:\n",
    "                    continue\n",
    "                \n",
    "                current_page_data.append(data)\n",
    "                \n",
    "            # --- Iterate through ALL criteria options (including the default one, which is now the primary action) ---\n",
    "            dropdown = driver.find_element(By.CSS_SELECTOR, \"div.rank-select\")\n",
    "            \n",
    "            for option_text in criteria_options_to_click_all:\n",
    "                \n",
    "                # We skip the click if this is the default criteria AND all rows were scored \n",
    "                # (avoids unnecessary click when data is already good).\n",
    "                if option_text == default_criteria_key and not unscored_row_indices:\n",
    "                    continue\n",
    "                    \n",
    "                # --- Dropdown Menu Interaction (Your Original Logic) ---\n",
    "                actions = ActionChains(driver)\n",
    "                actions.move_to_element(dropdown).click().perform()\n",
    "                actions.move_to_element(dropdown).click().perform()\n",
    "                \n",
    "                # Wait for the ul.options element to be visible\n",
    "                try:\n",
    "                    WebDriverWait(driver, 20).until(\n",
    "                        EC.visibility_of_element_located((By.XPATH, \"//ul[@class='options']\"))\n",
    "                    )\n",
    "                except TimeoutException:\n",
    "                    print(f\"Warning: Dropdown menu not visible for {option_text}. Skipping this criteria.\")\n",
    "                    continue\n",
    "                \n",
    "                # Use JavaScript to click the desired option\n",
    "                driver.execute_script(\n",
    "                    f\"\"\"\n",
    "                    const optionText = '{option_text}';\n",
    "                    const options = document.querySelectorAll('ul.options li');\n",
    "                    for (let i = 0; i < options.length; i++) {{\n",
    "                        if (options[i].textContent.trim() === optionText) {{\n",
    "                            options[i].click();\n",
    "                            break;\n",
    "                        }}\n",
    "                    }}\n",
    "                    \"\"\"\n",
    "                )\n",
    "                \n",
    "                # Wait for Table Data to refresh\n",
    "                time.sleep(1) \n",
    "                WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.CSS_SELECTOR, \"table.rk-table tbody tr\"))\n",
    "                )\n",
    "\n",
    "                # --- Extract Data for the Current Criteria (td[5]) ---\n",
    "                rows = driver.find_elements(By.CSS_SELECTOR, \"table.rk-table tbody tr\")\n",
    "\n",
    "                for i, row in enumerate(rows):\n",
    "                    if i >= len(current_page_data):\n",
    "                        continue\n",
    "                    \n",
    "                    try:\n",
    "                        cell_value = row.find_element(By.XPATH, \"./td[5]\").text.strip()\n",
    "                        current_page_data[i][option_text] = cell_value if cell_value else \"\"\n",
    "                    except NoSuchElementException:\n",
    "                        current_page_data[i][option_text] = \"\"\n",
    "                \n",
    "            # --- Close the dropdown and collect data ---\n",
    "            actions = ActionChains(driver)\n",
    "            actions.move_to_element(dropdown).click().perform()\n",
    "            \n",
    "            all_data_collected.extend(current_page_data)\n",
    "\n",
    "            # --- Pagination Logic (Restored Logic) ---\n",
    "            try:\n",
    "                next_button = WebDriverWait(driver, 10).until(\n",
    "                    EC.element_to_be_clickable((By.XPATH, \"//li[@title='下一页']\"))\n",
    "                )\n",
    "\n",
    "                if next_button.get_attribute(\"aria-disabled\") != \"true\":\n",
    "                    driver.execute_script(\"arguments[0].scrollIntoView();\", next_button)\n",
    "                    driver.execute_script(\"arguments[0].click();\", next_button)\n",
    "                    time.sleep(2)\n",
    "\n",
    "                    WebDriverWait(driver, 10).until(\n",
    "                        EC.presence_of_element_located((By.CSS_SELECTOR, \"table.rk-table tbody tr\"))\n",
    "                    )\n",
    "                    \n",
    "                    page_num += 1\n",
    "                else:\n",
    "                    print(f\"Reached the last page for year {year}. Exiting Loop\")\n",
    "                    break\n",
    "                \n",
    "            except (NoSuchElementException, TimeoutException) as e:\n",
    "                print(f\"Error or end of pages reached: {e}\")\n",
    "                break\n",
    "        \n",
    "        # Write all collected data once, after the pagination loop finishes\n",
    "        for data in all_data_collected:\n",
    "            writer.writerow([data.get(key, \"\") for key in header])\n",
    "        print(f\"Successfully extracted {len(all_data_collected)} rows.\")\n",
    "\n",
    "\n",
    "# --- Main Execution Loop ---\n",
    "print(\"--- Starting Scraper ---\")\n",
    "for year in range(2025,2026): \n",
    "    for subject_code, subject_name in subject_codes.items():\n",
    "        scrape_subject(year, subject_code, subject_name, driver)\n",
    "\n",
    "# --- Close WebDriver ---\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de85054f-c713-4e69-8082-26ec8e61d105",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
